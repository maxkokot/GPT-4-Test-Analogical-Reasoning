{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "### **Fase 1**\n",
        "\n",
        "1) Firstly, we need to ask ChatGPT the questions of type 1 from figure 1 of the article (file \".txt\"). This part is used, according to the article as a quality control by ensuring that ChatGPT is capable of recognizing the relation.\n",
        "\n",
        "2) Secondly, we need to ask ChatGPT the questions of type 2 from figure 1 of the article (file \".txt\"). Here the same prototype pairs are used as in the first part, but now we ask it to generate 4 new pairs with a similar relationship to the one used in these prototypes. Here we also need to specify that the direction of the relation is important **X->Y** or **Y->X**.\n",
        "\n",
        "As far as I understood, we need to ask each question from the first part together with the same pairs of the second part, like in the figure 1. So we are feeding ChatGPT with 2 questions every iteration - one from the first part, another from the second (for the same prototype pairs).\n",
        "\n",
        "### **Fase 2**\n",
        "\n",
        "We need to rank responses from **Fase 1** according to their prototypicality - for that we should use MaxDiff questions. (MaxDiff is a\n",
        "choice procedure consisting of a question about a\n",
        "target concept and four or five alternatives. A participant must choose both the best and worse answers\n",
        "from the given alternatives)\n",
        "\n",
        "1) Again we ask the first kind of questions (Question 1, figure 2 from the article). Again it serves as a quality control.\n",
        "\n",
        "2) In the second part ChatGPT should select the most and least\n",
        "illustrative example of that relation from among\n",
        "the four examples of pairs generated by it in\n",
        "**Phase 1**.\n",
        "\n",
        "And here, apparently, we need to apply MaxDiff questions again to assess the results.\n",
        "\n",
        "### **Notes about the data from what I understood**\n",
        "\n",
        "/Training/Phase1Questions - we have 10 files of type 1 question from Phase 1 for 3 different pairs each - as we need. We can extract these pairs separately for each file and create a \"card\" with the second type of question. However I haven't found the second type of question in the data, but since it's always the same ('... create your 4 pairs for the same relation ...') we can just define a string for this when feeding ChatGPT.\n",
        "\n",
        "/Training/Phase1Answers - in each file there are around 40 pairs generated by Turckers (the number is different in the files, like 41, 43, 44, etc). These are the predicted examples after asking questions of type 2. I don't know if we need to use these ones somewhere but we need to generate them ourselves."
      ],
      "metadata": {
        "id": "WG-zhHTcyb5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLICroWRxtaE",
        "outputId": "a6034068-c799-4da3-dbdc-0e76da5cf263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "!pip install --upgrade openai\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = 'YOUR API KEY'"
      ],
      "metadata": {
        "id": "xoJrwLyFx6DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the general structure for the second type of questions of Phase 1. We just need to extract the pairs for each of the 10 questions."
      ],
      "metadata": {
        "id": "nm79PK-KEsCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Type2QuestionPhase1Part_1 = \"\"\"Question 2: Consider the following word pairs: \"\"\" # then we need to add here the line with real pairs like this: \"pilgrim:shrine, hunter:quarry, assassin:victim, climber:peak.\"\n",
        "pairs = \"pilgrim:shrine, hunter:quarry, assassin:victim, climber:peak.\"\n",
        "Type2QuestionPhase1Part_2 = \"\"\"These X:Y pairs share a relation, “X R Y ”. Give four additional word pairs that illustrate the same relation, in the\n",
        "same order (X on the left, Y on the right). Please do not\n",
        "use phrases composed of two or more words in your examples (e.g., “racing car”). Please do not use names of\n",
        "people, places, or things in your examples (e.g., “Europe”,\n",
        "“Kleenex”).\"\"\"\n",
        "\n",
        "print(Type2QuestionPhase1Part_1 + pairs + Type2QuestionPhase1Part_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yTxZBAjAv06",
        "outputId": "0a008839-6cc4-4181-ad33-1b9b3ad6ca7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 2: Consider the following word pairs: pilgrim:shrine, hunter:quarry, assassin:victim, climber:peak.These X:Y pairs share a relation, “X R Y ”. Give four additional word pairs that illustrate the same relation, in the\n",
            "same order (X on the left, Y on the right). Please do not\n",
            "use phrases composed of two or more words in your examples (e.g., “racing car”). Please do not use names of\n",
            "people, places, or things in your examples (e.g., “Europe”,\n",
            "“Kleenex”).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following script reads all 10 questions from the Phase 1 folder and stores it as lines in a dictionary. It stores the part of them starting from \"Consider the following ...\" ending with the last example of four possible relations."
      ],
      "metadata": {
        "id": "fVGhYID9DhM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        start_idx = content.find(\"Consider the following word pairs:\")\n",
        "        end_idx = content.find(\"Correct Answer:\")\n",
        "        if start_idx != -1 and end_idx != -1:\n",
        "            return content[start_idx:end_idx].strip()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "def process_files(folder_path):\n",
        "    extracted_texts = {}\n",
        "    for index, filename in enumerate(os.listdir(folder_path)):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            extracted_text = extract_text(file_path)\n",
        "            if extracted_text:\n",
        "                extracted_texts[index] = extracted_text\n",
        "    return extracted_texts\n",
        "\n",
        "folder_path = '/content/Training/Phase1Questions'\n",
        "Type1QuestionsPhase1 = process_files(folder_path) # these are full questions, we can directly feed them into ChatGPT\n",
        "print(Type1QuestionsPhase1)\n",
        "\n",
        "def extract_and_join_word_pairs(data_dict):\n",
        "    word_pairs_dict = {}\n",
        "    for key, text in data_dict.items():\n",
        "        lines = text.split('\\n')\n",
        "        pairs = []\n",
        "        for line in lines:\n",
        "            if ':' in line and not line.startswith(\"Consider\") and not line.startswith('What'):\n",
        "                pairs.append(line.strip())\n",
        "        word_pairs_dict[key] = '; '.join(pairs)\n",
        "    return word_pairs_dict\n",
        "\n",
        "joined_word_pairs = extract_and_join_word_pairs(Type1QuestionsPhase1)\n",
        "print(joined_word_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhIqUIaVCO5P",
        "outputId": "d0694319-828b-4eeb-a757-344f1e379b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Consider the following word pairs:\\n\\ncar:auto\\nbuy:purchase\\nrapid:quick\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nY is an instrument through with X receives some object/service/role\\nan X and Y are a similar type of action/thing/attribute\\nsomeone perform the action X on Y\\nsomeone/something who is X is unlikely to Y', 1: 'Consider the following word pairs:\\n\\nmillionaire:money\\nauthor:copyright\\nrobin:nest\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nX causes/compels a person to Y\\nX is intended to produce Y\\nan X cannot have attribute Y; Y is antithetical to being X\\nX possesses/owns/has Y', 2: 'Consider the following word pairs:\\n\\nflower:tulip\\nemotion:rage\\npoem:sonnet\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nto X is to have a Y receive some object/service/idea\\nY is an unacceptable form of X\\na Y is a part of an X\\nY is a kind/type/instance of X', 3: 'Consider the following word pairs:\\n\\ntailor:suit\\noracle:prophesy\\nbaker:flour\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nsomething that is X cannot be Y\\nan X makes Y / an X uses Y to make an item\\nX is intended to produce Y\\nX enables the use of Y', 4: 'Consider the following word pairs:\\n\\nattack:defend\\nbuy:sell\\nlove:hate\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nX is the reverse act of Y / X may be undone by Y\\nX is an expression that indicates Y\\na Y represents/is representative of X\\nY describes a condition or state that is usually absent from X', 5: 'Consider the following word pairs:\\n\\nwater:drop\\nmile:yard\\ntime:moment\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nan X is an increase/decease in Y\\nan Y receives an X\\nan X is is a defect in Y\\nX may be divided into Y', 6: 'Consider the following word pairs:\\n\\nrain:wet\\nriddle:holes\\nhomogenize:uniform\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nthe action X results Y or things that are Y\\na Y represents/is representative of X\\nX and Y are contrary / opposite to each other\\na Y is one item in a collection/group of X', 7: 'Consider the following word pairs:\\n\\ncontentious:conflict\\ntaciturn:silence\\ncelibate:abstinence\\n\\nWhat relation best describes these X:Y word pairs?\\n\\na person who is X often is in a state of Y\\nX is an expression that indicates Y\\nX is a time when Y occurs\\nX will become / be converted into Y', 8: 'Consider the following word pairs:\\n\\nsiren:danger\\nscepter:authority\\nsignature:approval\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nan X is a place/location/area where Y takes place\\nan X indicates/signifies Y\\nan X will typically Y\\nsomeone/something who is X cannot be Y or be in the state of Y', 9: 'Consider the following word pairs:\\n\\neating:gluttony\\nconcerned:obsessed\\nbleeding:hemorrhage\\n\\nWhat relation best describes these X:Y word pairs?\\n\\nBeing X is incompatible with being Y\\nX is made of / is comprised of Y\\nsomeone/something will X in order to Y\\nY is an excessive form of X'}\n",
            "{0: 'car:auto; buy:purchase; rapid:quick', 1: 'millionaire:money; author:copyright; robin:nest', 2: 'flower:tulip; emotion:rage; poem:sonnet', 3: 'tailor:suit; oracle:prophesy; baker:flour', 4: 'attack:defend; buy:sell; love:hate', 5: 'water:drop; mile:yard; time:moment', 6: 'rain:wet; riddle:holes; homogenize:uniform', 7: 'contentious:conflict; taciturn:silence; celibate:abstinence', 8: 'siren:danger; scepter:authority; signature:approval', 9: 'eating:gluttony; concerned:obsessed; bleeding:hemorrhage'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": Type1QuestionsPhase1[0], # taking the first question from the dictionary\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\", # choosing the model\n",
        ")"
      ],
      "metadata": {
        "id": "Gb2cLJ1KLxXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion\n",
        "\n",
        "# The answer here looks like this:\n",
        "\"\"\"\n",
        "ChatCompletion(id='chatcmpl-8RiDrElxkDf2cGXFQ0axunf9x4uda', choices=[Choice(finish_reason='stop', index=0,\n",
        "message=ChatCompletionMessage(content='Y is an instrument through which X receives some object/service/role',\n",
        "role='assistant', function_call=None, tool_calls=None))], created=1701615539, model='gpt-3.5-turbo-0613', object='chat.completion',\n",
        "system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=82, total_tokens=95))\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsTDGH0VMKSJ",
        "outputId": "7c93162b-9429-47cc-ac47-eadb142ed1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8RiDrElxkDf2cGXFQ0axunf9x4uda', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Y is an instrument through which X receives some object/service/role', role='assistant', function_call=None, tool_calls=None))], created=1701615539, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=82, total_tokens=95))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part is for automatic running through the dictionary, but to be fixed, it doesn't like that a loop is used"
      ],
      "metadata": {
        "id": "i4-6eHFEMW3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def ask_openai(questions_dict):\n",
        "    responses = {}\n",
        "    for key, question in questions_dict.items():\n",
        "        try:\n",
        "            # Sending the question to OpenAI's API using the new interface\n",
        "            chat_completion = client.chat.completions.create(\n",
        "                messages=[{\"role\": \"user\", \"content\": question}],\n",
        "                model=\"gpt-3.5-turbo\",  # Or another model you prefer\n",
        "            )\n",
        "            # Extracting the response text properly\n",
        "            response_text = chat_completion.choices[0].message['content'].strip()\n",
        "            responses[key] = response_text\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred with question {key}: {e}\")\n",
        "            responses[key] = \"Error\"\n",
        "    return responses\n",
        "\n",
        "# Assuming your dictionary is named 'Type1QuestionsPhase1'\n",
        "responses_dict = ask_openai(Type1QuestionsPhase1)\n",
        "print(responses_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "x8iln57FIQcq",
        "outputId": "9785db24-76ea-4fc7-c0fa-a4219a383fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred with question 0: 'ChatCompletionMessage' object is not subscriptable\n",
            "An error occurred with question 1: 'ChatCompletionMessage' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6fe84eda54ff>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Assuming your dictionary is named 'Type1QuestionsPhase1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mresponses_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mType1QuestionsPhase1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-6fe84eda54ff>\u001b[0m in \u001b[0;36mask_openai\u001b[0;34m(questions_dict)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# Sending the question to OpenAI's API using the new interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             chat_completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Or another model you prefer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 598\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         )\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 856\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_auth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    930\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0;31m# The ConnectionNotAvailable exception is a special case, that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mreason_phrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    112\u001b[0m                 trace.return_value = (\n\u001b[1;32m    113\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    213\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuation with parsing"
      ],
      "metadata": {
        "id": "9i2OczOcx_D1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing the number of files in the folder and creation of a folder with output files"
      ],
      "metadata": {
        "id": "W-KmSeFvyJQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data_CBSD.zip"
      ],
      "metadata": {
        "id": "B8cwgkXwyu8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "def process_files(input_folder, output_folder, k):\n",
        "    files = os.listdir(input_folder)[:k]  # Get first k files\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in files:\n",
        "        unique_lines = {}\n",
        "        relation = \"\"\n",
        "\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile:\n",
        "            reader = csv.reader((line.replace('\\t', '\\t') for line in infile), delimiter='\\t')\n",
        "            next(reader, None)  # Skip header if exists\n",
        "\n",
        "            for i, row in enumerate(reader):\n",
        "                if i == 0:  # Extract relation from the second row (i.e., first data row)\n",
        "                    relation = row[-1] if len(row) > 6 else \"\"\n",
        "                if len(row) >= 7:  # Ensure the row has enough columns\n",
        "                    key = tuple(row[:4])  # First 4 columns as key\n",
        "                    least_most = tuple(row[4:6])  # least_illustrative and most_illustrative\n",
        "                    if key not in unique_lines:\n",
        "                        unique_lines[key] = []\n",
        "                    unique_lines[key].append(least_most)\n",
        "\n",
        "        with open(os.path.join(output_folder, file), 'w', newline='') as outfile:\n",
        "            writer = csv.writer(outfile, delimiter='\\t')\n",
        "            writer.writerow([relation])  # Write the relation as the first line\n",
        "            for key, values in unique_lines.items():\n",
        "                if values:\n",
        "                    most_common = Counter(values).most_common(1)[0][0]\n",
        "                    writer.writerow(list(key) + list(most_common))\n",
        "                else:\n",
        "                    writer.writerow(list(key) + [\"\", \"\"])  # Empty values for missing data\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/Testing/Phase2Answers'  # Adjust to your input folder path\n",
        "output_folder = '/content/output_files'  # Adjust to your output folder path\n",
        "k = 1  # Number of files to process\n",
        "process_files(input_folder, output_folder, k)"
      ],
      "metadata": {
        "id": "W0k-Kbf83WNx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_no_most_least_files(input_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in os.listdir(input_folder):\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile, \\\n",
        "             open(os.path.join(output_folder, file.replace('.txt', '_no_least_most.txt')), 'w', newline='') as outfile:\n",
        "            reader = csv.reader(infile, delimiter='\\t')\n",
        "            writer = csv.writer(outfile, delimiter='\\t')\n",
        "\n",
        "            for i, row in enumerate(reader):\n",
        "                if i == 0:  # Copy the first line as is (relation)\n",
        "                    writer.writerow(row)\n",
        "                else:\n",
        "                    writer.writerow(row[:4])  # Write only the first four columns\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/output_files'  # Adjust to your input folder path\n",
        "output_folder = '/content/output_no_least_most'  # Adjust to your output folder path\n",
        "create_no_most_least_files(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "kpwO7iWF3jG3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT feeding"
      ],
      "metadata": {
        "id": "H9G8ZOraRllZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_files_and_query_gpt(input_folder, output_folder, api_key):\n",
        "    openai.api_key = api_key  # Set the API key for OpenAI\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in os.listdir(input_folder):\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile:\n",
        "            reader = csv.reader(infile, delimiter='\\t')\n",
        "            relation = next(reader, [])[0]  # First row for the relation\n",
        "            pairs = [row for row in reader]\n",
        "\n",
        "            # Construct dynamic instructions including the relation\n",
        "            # instructions = (\"I'm going to give you several lines of the same type. \"\n",
        "            #                 \"Your task is for each line to output the least illustrative \"\n",
        "            #                 \"and the most illustrative representation of this relation: '\"\n",
        "            #                 + relation + \"' (the order is important here!). \"\n",
        "            #                 \"So, the output should be multiple lines with 2 pairs: \"\n",
        "            #                 \"least illustrative and most illustrative. Output only this \"\n",
        "            #                 \"information without any other comments.\")\n",
        "            instructions = (\"For each line, output the least illustrative \"\n",
        "                            \"and the most illustrative representation of this relation: '\"\n",
        "                            + relation + \"'. The output should be two pairs: \"\n",
        "                            \"least illustrative and most illustrative.\")\n",
        "\n",
        "            # Divide into batches of max 20 lines\n",
        "            batches = [pairs[i:i + 20] for i in range(0, len(pairs), 20)]\n",
        "            responses = []\n",
        "\n",
        "            for batch in batches:\n",
        "                # Prepare messages for API call, including the instructions\n",
        "                messages = [{\"role\": \"system\", \"content\": instructions}]\n",
        "                messages.extend([{\"role\": \"user\", \"content\": \" \".join(row)} for row in batch])\n",
        "\n",
        "                # Make API calls using chat completions\n",
        "                chat_completion = openai.ChatCompletion.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=messages\n",
        "                )\n",
        "                # Correctly extracting the assistant's response\n",
        "                assistant_message = chat_completion['choices'][0]['message']\n",
        "                if assistant_message['role'] == 'assistant':\n",
        "                    responses.append(assistant_message['content'])\n",
        "\n",
        "            # Write to new file\n",
        "            with open(os.path.join(output_folder, file.replace('.txt', '_gpt.txt')), 'w', newline='') as outfile:\n",
        "                writer = csv.writer(outfile, delimiter='\\t')\n",
        "                writer.writerow([relation])\n",
        "                for response in responses:\n",
        "                    writer.writerow([response])\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/output_no_least_most'\n",
        "output_folder = '/content/output_gpt'\n",
        "api_key = ''  # Replace with your actual API key\n",
        "process_files_and_query_gpt(input_folder, output_folder, api_key)"
      ],
      "metadata": {
        "id": "PcpB6yaDQV2t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_files_and_query_gpt(input_folder, output_folder, api_key):\n",
        "    openai.api_key = api_key  # Set the API key for OpenAI\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in os.listdir(input_folder):\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile:\n",
        "            reader = csv.reader(infile, delimiter='\\t')\n",
        "            relation = next(reader, [])[0]  # First row for the relation\n",
        "\n",
        "            # Update instructions including the relation\n",
        "            instructions = (\"In this line, based on the pairs provided, choose among them the least illustrative \"\n",
        "                            \"and the most illustrative representation for this relation: '\"\n",
        "                            + relation + \"' (the order of the relation matters). The output should be these four pairs \"\n",
        "                            \"and the least illustrative and the most illustrative as the 5th and 6th column, accordingly.\"\n",
        "                            \"The output should be written in one line, 6 pairs overall in the following format:\"\n",
        "                            \"pair1, pair2, pair3, pair4, least_illustrative, most_illustrative \"\n",
        "                            \"And that's it, no brackets, no quotes, nothing else, it must be in this format.\")\n",
        "\n",
        "            responses = []\n",
        "\n",
        "            for pairs in reader:\n",
        "                # Prepare the message for API call, including the instructions and the line\n",
        "                message = [{\"role\": \"system\", \"content\": instructions},\n",
        "                           {\"role\": \"user\", \"content\": \" \".join(pairs)}]\n",
        "\n",
        "                # Make API calls for each line\n",
        "                chat_completion = openai.ChatCompletion.create(\n",
        "                    model=\"gpt-4\",\n",
        "                    messages=message\n",
        "                )\n",
        "                # Extracting the assistant's response\n",
        "                assistant_message = chat_completion['choices'][0]['message']\n",
        "                if assistant_message['role'] == 'assistant':\n",
        "                    responses.append(assistant_message['content'])\n",
        "\n",
        "            # Write to new file\n",
        "            with open(os.path.join(output_folder, file.replace('.txt', '_gpt.txt')), 'w', newline='') as outfile:\n",
        "                writer = csv.writer(outfile, delimiter='\\t')\n",
        "                writer.writerow([relation])\n",
        "                for response in responses:\n",
        "                    writer.writerow([response])\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/output_no_least_most'\n",
        "output_folder = '/content/output_gpt'\n",
        "api_key = ''  # Replace with your actual API key\n",
        "process_files_and_query_gpt(input_folder, output_folder, api_key)\n"
      ],
      "metadata": {
        "id": "G17ESBUpWhSn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MyK4My7cbpoF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}