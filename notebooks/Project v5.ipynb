{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Continuation with parsing (updated 17.12.2023)"
      ],
      "metadata": {
        "id": "9i2OczOcx_D1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing the number of files in the folder and creation of a folder with output files"
      ],
      "metadata": {
        "id": "W-KmSeFvyJQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data_CBSD.zip"
      ],
      "metadata": {
        "id": "B8cwgkXwyu8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "def process_files(input_folder, output_folder, k):\n",
        "    files = os.listdir(input_folder)[:k]  # Get first k files\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in files:\n",
        "        unique_lines = {}\n",
        "        relation = \"\"\n",
        "\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile:\n",
        "            reader = csv.reader((line.replace('\\t', '\\t') for line in infile), delimiter='\\t')\n",
        "            next(reader, None)  # Skip header if exists\n",
        "\n",
        "            for i, row in enumerate(reader):\n",
        "                if i == 0:  # Extract relation from the second row (i.e., first data row)\n",
        "                    relation = row[-1] if len(row) > 6 else \"\"\n",
        "                if len(row) >= 7:  # Ensure the row has enough columns\n",
        "                    key = tuple(row[:4])  # First 4 columns as key\n",
        "                    least_most = tuple(row[4:6])  # least_illustrative and most_illustrative\n",
        "                    if key not in unique_lines:\n",
        "                        unique_lines[key] = []\n",
        "                    unique_lines[key].append(least_most)\n",
        "\n",
        "        with open(os.path.join(output_folder, file), 'w', newline='') as outfile:\n",
        "            writer = csv.writer(outfile, delimiter='\\t')\n",
        "            writer.writerow([relation])  # Write the relation as the first line\n",
        "            for key, values in unique_lines.items():\n",
        "                if values:\n",
        "                    most_common = Counter(values).most_common(1)[0][0]\n",
        "                    writer.writerow(list(key) + list(most_common))\n",
        "                else:\n",
        "                    writer.writerow(list(key) + [\"\", \"\"])  # Empty values for missing data\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/Testing/Phase2Answers'  # Adjust to your input folder path\n",
        "output_folder = '/content/output_files'  # Adjust to your output folder path\n",
        "k = 8  # Number of files to process\n",
        "process_files(input_folder, output_folder, k)"
      ],
      "metadata": {
        "id": "W0k-Kbf83WNx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_no_most_least_files(input_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in os.listdir(input_folder):\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile, \\\n",
        "             open(os.path.join(output_folder, file.replace('.txt', '_no_least_most.txt')), 'w', newline='') as outfile:\n",
        "            reader = csv.reader(infile, delimiter='\\t')\n",
        "            writer = csv.writer(outfile, delimiter='\\t')\n",
        "\n",
        "            for i, row in enumerate(reader):\n",
        "                if i == 0:  # Copy the first line as is (relation)\n",
        "                    writer.writerow(row)\n",
        "                else:\n",
        "                    writer.writerow(row[:4])  # Write only the first four columns\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/output_files'  # Adjust to your input folder path\n",
        "output_folder = '/content/output_no_least_most'  # Adjust to your output folder path\n",
        "create_no_most_least_files(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "kpwO7iWF3jG3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT feeding"
      ],
      "metadata": {
        "id": "H9G8ZOraRllZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is a draft useful for the report, don't run it\n",
        "\n",
        "def process_files_and_query_gpt(input_folder, output_folder, api_key):\n",
        "    openai.api_key = api_key  # Set the API key for OpenAI\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in os.listdir(input_folder):\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile:\n",
        "            reader = csv.reader(infile, delimiter='\\t')\n",
        "            relation = next(reader, [])[0]  # First row for the relation\n",
        "            pairs = [row for row in reader]\n",
        "\n",
        "            # Construct dynamic instructions including the relation\n",
        "            # instructions = (\"I'm going to give you several lines of the same type. \"\n",
        "            #                 \"Your task is for each line to output the least illustrative \"\n",
        "            #                 \"and the most illustrative representation of this relation: '\"\n",
        "            #                 + relation + \"' (the order is important here!). \"\n",
        "            #                 \"So, the output should be multiple lines with 2 pairs: \"\n",
        "            #                 \"least illustrative and most illustrative. Output only this \"\n",
        "            #                 \"information without any other comments.\")\n",
        "            instructions = (\"For each line, output the least illustrative \"\n",
        "                            \"and the most illustrative representation of this relation: '\"\n",
        "                            + relation + \"'. The output should be two pairs: \"\n",
        "                            \"least illustrative and most illustrative.\")\n",
        "\n",
        "            # Divide into batches of max 20 lines\n",
        "            batches = [pairs[i:i + 20] for i in range(0, len(pairs), 20)]\n",
        "            responses = []\n",
        "\n",
        "            for batch in batches:\n",
        "                # Prepare messages for API call, including the instructions\n",
        "                messages = [{\"role\": \"system\", \"content\": instructions}]\n",
        "                messages.extend([{\"role\": \"user\", \"content\": \" \".join(row)} for row in batch])\n",
        "\n",
        "                # Make API calls using chat completions\n",
        "                chat_completion = openai.ChatCompletion.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=messages\n",
        "                )\n",
        "                # Correctly extracting the assistant's response\n",
        "                assistant_message = chat_completion['choices'][0]['message']\n",
        "                if assistant_message['role'] == 'assistant':\n",
        "                    responses.append(assistant_message['content'])\n",
        "\n",
        "            # Write to new file\n",
        "            with open(os.path.join(output_folder, file.replace('.txt', '_gpt.txt')), 'w', newline='') as outfile:\n",
        "                writer = csv.writer(outfile, delimiter='\\t')\n",
        "                writer.writerow([relation])\n",
        "                for response in responses:\n",
        "                    writer.writerow([response])\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/output_no_least_most'\n",
        "output_folder = '/content/output_gpt'\n",
        "api_key = ''  # Replace with your actual API key\n",
        "process_files_and_query_gpt(input_folder, output_folder, api_key)"
      ],
      "metadata": {
        "id": "PcpB6yaDQV2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the core cell, the instruction is sufficient\n",
        "\n",
        "!pip install openai==0.28\n",
        "import openai\n",
        "\n",
        "def process_files_and_query_gpt(input_folder, output_folder, api_key):\n",
        "    openai.api_key = api_key  # Set the API key for OpenAI\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file in os.listdir(input_folder):\n",
        "        with open(os.path.join(input_folder, file), 'r') as infile:\n",
        "            reader = csv.reader(infile, delimiter='\\t')\n",
        "            relation = next(reader, [])[0]  # First row for the relation\n",
        "\n",
        "            # Update instructions including the relation\n",
        "            instructions = (\"In this line, based on the pairs provided, choose among them the least illustrative \"\n",
        "                            \"and the most illustrative representation for this relation: '\"\n",
        "                            + relation + \"' (the order of the relation matters). The output should be these four pairs \"\n",
        "                            \"and the least illustrative and the most illustrative as the 5th and 6th column, accordingly.\"\n",
        "                            \"The output should be written in one line, 6 pairs overall in the following format:\"\n",
        "                            \"pair1, pair2, pair3, pair4, least_illustrative, most_illustrative \"\n",
        "                            \"And that's it, no brackets, no quotes, nothing else, it must be in this format.\")\n",
        "\n",
        "            responses = []\n",
        "\n",
        "            for pairs in reader:\n",
        "                # Prepare the message for API call, including the instructions and the line\n",
        "                message = [{\"role\": \"system\", \"content\": instructions},\n",
        "                           {\"role\": \"user\", \"content\": \" \".join(pairs)}]\n",
        "\n",
        "                # Make API calls for each line\n",
        "                chat_completion = openai.ChatCompletion.create(\n",
        "                    model=\"gpt-4\",\n",
        "                    messages=message\n",
        "                )\n",
        "                # Extracting the assistant's response\n",
        "                assistant_message = chat_completion['choices'][0]['message']\n",
        "                if assistant_message['role'] == 'assistant':\n",
        "                    responses.append(assistant_message['content'])\n",
        "\n",
        "            # Write to new file\n",
        "            with open(os.path.join(output_folder, file.replace('.txt', '_gpt.txt')), 'w', newline='') as outfile:\n",
        "                writer = csv.writer(outfile, delimiter='\\t')\n",
        "                writer.writerow([relation])\n",
        "                for response in responses:\n",
        "                    writer.writerow([response])\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/output_no_least_most'\n",
        "output_folder = '/content/output_gpt'\n",
        "api_key = ''  # Replace with your actual API key\n",
        "process_files_and_query_gpt(input_folder, output_folder, api_key)"
      ],
      "metadata": {
        "id": "G17ESBUpWhSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ea5975-11fe-4cca-8dd0-d9e9395f81ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def create_lists(combination, path_correct, path_gpt):\n",
        "    # Filenames based on the combination\n",
        "    filename_correct = f'Phase2Answers-{combination}.txt'\n",
        "    filename_gpt = f'Phase2Answers-{combination}_no_least_most_gpt.txt'\n",
        "\n",
        "    # Initialize lists\n",
        "    leasts_correct = []\n",
        "    mosts_correct = []\n",
        "    leasts_gpt = []\n",
        "    mosts_gpt = []\n",
        "\n",
        "    # Process the file from the correct folder\n",
        "    with open(os.path.join(path_correct, filename_correct), 'r') as file:\n",
        "        reader = csv.reader(file, delimiter='\\t')\n",
        "        next(reader)  # Skip the first line (relation)\n",
        "        for row in reader:\n",
        "            leasts_correct.append(row[4])\n",
        "            mosts_correct.append(row[5])\n",
        "\n",
        "    # Process the file from the gpt folder\n",
        "    with open(os.path.join(path_gpt, filename_gpt), 'r') as file:\n",
        "        reader = csv.reader(file, delimiter=',')\n",
        "        next(reader)  # Skip the first line (relation)\n",
        "        for row in reader:\n",
        "            cleaned_row = [element.strip() for element in row]\n",
        "            if len(cleaned_row) >= 6:\n",
        "                leasts_gpt.append(cleaned_row[4])\n",
        "                mosts_gpt.append(cleaned_row[5])\n",
        "\n",
        "    return leasts_correct, mosts_correct, leasts_gpt, mosts_gpt\n",
        "\n",
        "# Example usage\n",
        "combination = '10b'\n",
        "path_correct = '/content/output_files'\n",
        "path_gpt = '/content/output_gpt'\n",
        "leasts_correct, mosts_correct, leasts_gpt, mosts_gpt = create_lists(combination, path_correct, path_gpt)"
      ],
      "metadata": {
        "id": "MyK4My7cbpoF"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(leasts_correct))\n",
        "print(leasts_correct)\n",
        "print(len(leasts_gpt))\n",
        "print(leasts_gpt)\n",
        "\n",
        "print('##############')\n",
        "\n",
        "print(len(mosts_correct))\n",
        "print(mosts_correct)\n",
        "print(len(mosts_gpt))\n",
        "print(mosts_gpt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PENwvFN02DY0",
        "outputId": "37155724-92f0-402b-9db3-6fb3d5fc92b7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "['friendliness:wink', 'growl:danger', 'discourse:relationship', 'frown:anger', 'sigh:exhaustion', 'wink:friendliness', 'wave:acknowledgment', 'friendliness:wink', 'hilarity:laugh', 'exhaustion:sigh', 'glare:anger', 'cough:sickness', 'anger:slap', 'hilarity:laugh', 'hilarity:laugh', 'exhaustion:sigh', 'growl:danger', 'glare:anger', 'anger:slap', 'glare:anger', 'hilarity:laugh', 'frown:sadness', 'wink:friendliness', 'kiss:passion', 'anger:slap', 'lie:dishonesty', 'growl:danger', 'sorrow:tears', 'friendliness:wink', 'wave:acknowledgment', 'friendliness:wink', 'anger:slap', 'snarl:anger', 'glare:anger', 'cough:illness', 'hilarity:laugh', 'wink:friendliness', 'sigh:exhaustion', 'sorrow:tears', 'slap:anger', 'hilarity:laugh', 'frown:discontent', 'frown:distaste', 'exhaustion:sigh', 'friendliness:wink', 'yawn:boredom', 'wink:friendliness', 'anger:slap', 'friendliness:wink', 'exhaustion:sigh', 'nod:agreement', 'crying:sadness', 'frown:distaste', 'discourse:relationship', 'nod:agreement', 'exhaustion:sigh', 'exhaustion:sigh', 'handshake:cordiality', 'exhaustion:sigh', 'burp:gas', 'sorrow:tears', 'grimace:disgust', 'friendliness:wink', 'slap:anger', 'tears:sorrow', 'hilarity:laugh', 'burp:gas', 'friendliness:wink', 'growl:danger', 'sorrow:tears', 'laugh:hilarity', 'frown:anger', 'cough:illness', 'punch:hatred', 'yawn:boredom', 'sorrow:tears', 'handshake:cordiality', 'hilarity:laugh', 'discourse:relationship', 'wink:friendliness', 'laugh:hilarity', 'wink:friendliness', 'exhaustion:sigh', 'frown:distaste', 'friendliness:wink', 'discourse:relationship', 'yawn:boredom', 'tear:sadness', 'tear:sadness', 'discourse:relationship', 'sorrow:tears', 'frown:sadness', 'scream:terror', 'frown:anger', 'discourse:relationship', 'wink:friendliness', 'burp:gas', 'tears:sadness', 'discourse:relationship', 'cough:illness']\n",
            "100\n",
            "['friendliness:wink', 'anger:slap', 'punch:hatred', 'handshake:cordiality', 'friendliness:wink', 'exhaustion:sigh', 'kiss:passion', 'friendliness:wink', 'hilarity:laugh', 'discourse:relationship', 'sorrow:tears', 'cough:sickness', 'anger:slap', 'burp:gas', 'hilarity:laugh', 'exhaustion:sigh', 'punch:hatred', 'handshake:cordiality', 'anger:slap', 'wave:acknowledgment', 'slap:anger', 'laugh:amusement', 'wink:friendliness', 'punch:hatred', 'anger:slap', 'lie:dishonesty', 'frown:sadness', 'anger:slap', 'friendliness:wink', 'slap:anger', 'friendliness:wink', 'anger:slap', 'nod:agreement', 'kiss:passion', 'lie:dishonesty', '', 'wink:friendliness', 'slap:anger', 'sorrow:tears', 'slap:anger', 'cough:illness', 'snarl:anger', 'slap:anger', 'glare:anger', 'friendliness:wink', 'burp:gas', 'punch:hatred', 'anger:slap', 'anger:slap', 'exhaustion:sigh', 'frown:distaste', 'wave:acknowledgment', 'frown:distaste', 'discourse:relationship', 'burp:gas', 'exhaustion:sigh', 'anger:slap', 'slap:anger', 'exhaustion:sigh', 'burp:gas', 'sorrow:tears', 'kiss:love', 'slap:anger', 'cough:illness', 'burp:gas', 'hilarity:laugh', 'burp:gas', 'friendliness:wink', 'growl:danger', 'frown:anger', 'laugh:hilarity', 'wave:acknowledgement', 'sorrow:tears', 'punch:hatred', 'kiss:love', 'sorrow:tears', 'hilarity:laugh', 'laugh:happiness', 'cough:sickness', 'wink:friendliness', 'cough:sickness', 'wink:friendliness', 'lie:dishonesty', 'frown:distaste', 'sorrow:tears', 'discourse:relationship', 'yawn:boredom', 'punch:hatred', 'laugh:happiness', 'discourse:relationship', 'sorrow:tears', 'tear:sadness', 'handshake:cordiality', 'burp:gas', 'discourse:relationship', 'wink:friendliness', 'burp:gas', 'frown:discontent', 'discourse:relationship', 'cough:illness']\n",
            "##############\n",
            "100\n",
            "['tears:sadness', 'cough:sickness', 'yell:anger', 'tears:sorrow', 'nod:agreement', 'kiss:love', 'kiss:passion', 'crying:sadness', 'tear:sadness', 'tears:sadness', 'sorrow:tears', 'laugh:happiness', 'cough:sickness', 'nod:agreement', 'groan:pain', 'tears:sorrow', 'laugh:amusement', 'yawn:boredom', 'laugh:amusement', 'lie:dishonesty', 'cough:sickness', 'snarl:anger', 'groan:pain', 'wave:acknowledgement', 'frown:discontent', 'laugh:amusement', 'crying:sadness', 'laugh:happiness', 'scream:terror', 'lie:dishonesty', 'laugh:amusement', 'laugh:happiness', 'crying:sadness', 'nod:agreement', 'lie:dishonesty', 'laugh:hilarity', 'grimace:disgust', 'laugh:amusement', 'groan:pain', 'tears:sorrow', 'cough:illness', 'crying:sadness', 'yell:anger', 'tears:sadness', 'frown:sadness', 'grimace:disgust', 'laugh:hilarity', 'tears:sadness', 'handshake:cordiality', 'tear:sadness', 'nod:agreement', 'kiss:passion', 'tears:sadness', 'kiss:love', 'frown:sadness', 'handshake:cordiality', 'kiss:love', 'slap:anger', 'yawn:boredom', 'grimace:disgust', 'tears:sorrow', 'groan:pain', 'glare:anger', 'kiss:love', 'burp:gas', 'tears:sorrow', 'tears:sadness', 'tears:sadness', 'laughter:amusement', 'snarl:anger', 'laugh:amusement', 'snarl:anger', 'snarl:anger', 'grimace:disgust', 'laughter:amusement', 'wave:acknowledgement', 'laugh:amusement', 'laugh:happiness', 'kiss:love', 'sigh:exhaustion', 'scream:terror', 'lie:dishonesty', 'tear:sadness', 'wave:acknowledgement', 'sorrow:tears', 'cough:illness', 'laugh:hilarity', 'cough:sickness', 'sigh:exhaustion', 'laughter:amusement', 'tear:sadness', 'tear:sadness', 'handshake:cordiality', 'grimace:disgust', 'nod:agreement', 'laugh:happiness', 'laugh:happiness', 'kiss:love', 'groan:pain', 'nod:agreement']\n",
            "100\n",
            "['tears:sadness', 'crying:sadness', 'sigh:exhaustion', 'tears:sorrow', 'yawn:boredom', 'frown:anger', 'wave:acknowledgment', 'snarl:anger', 'yawn:boredom', 'tears:sadness', 'frown:discontent', 'laughter:amusement', 'cough:sickness', 'nod:agreement', 'laughter:amusement', 'tears:sorrow', 'laugh:amusement', 'growl:danger', 'yell:anger', 'frown:discontent', 'frown:anger', 'grimace:disgust', 'groan:pain', 'sigh:exhaustion', 'growl:danger', 'laugh:amusement', 'crying:sadness', 'wink:friendliness', 'scream:terror', 'frown:sadness', 'growl:danger', 'laugh:happiness', 'scream:terror', 'glare:anger', 'sigh:exhaustion', '', 'tears:sadness', 'laugh:amusement', 'groan:pain', 'crying:sadness', 'frown:distaste', 'tears:sorrow', 'yell:anger', 'crying:sadness', 'tears:sorrow', 'sigh:exhaustion', 'laugh:hilarity', 'tears:sadness', 'handshake:cordiality', 'tear:sadness', 'nod:agreement', 'yell:anger', 'tears:sadness', 'yell:anger', 'scream:terror', 'growl:danger', 'kiss:love', 'laugh:happiness', 'yawn:boredom', 'nod:agreement', 'groan:pain', 'groan:pain', 'exhaustion:sigh', 'scream:terror', 'laugh:happiness', 'tears:sadness', 'tears:sadness', 'frown:anger', 'frown:anger', 'sorrow:tears', 'kiss:love', 'groan:pain', 'snarl:anger', 'yell:anger', 'tear:sadness', 'wave:acknowledgement', 'handshake:cordiality', 'hilarity:laugh', 'discourse:relationship', 'crying:sadness', 'scream:terror', 'frown:sadness', 'laugh:hilarity', 'laugh:hilarity', 'laugh:hilarity', 'glare:anger', 'laugh:hilarity', 'tear:sadness', 'frown:anger', 'wave:acknowledgment', 'frown:discontent', 'scream:terror', 'scream:terror', 'grimace:disgust', 'growl:danger', 'laugh:happiness', 'yell:anger', 'laughter:amusement', 'scream:terror', 'nod:agreement']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_lists(list1, list2):\n",
        "    if len(list1) != len(list2):\n",
        "        print(\"Lists are of different lengths. Cannot compare element-wise.\")\n",
        "        return\n",
        "\n",
        "    matched = 0\n",
        "    for i in range(len(list1)):\n",
        "        if list1[i] == list2[i]:\n",
        "            matched += 1\n",
        "        else:\n",
        "            print(f\"Mismatch at index {i}: '{list1[i]}' (List1) vs '{list2[i]}' (List2)\")\n",
        "\n",
        "    print(f\"Total matches: {matched} out of {len(list1)}\")\n",
        "\n",
        "# Example usage with your lists\n",
        "print(\"Comparing least illustrative pairs:\")\n",
        "compare_lists(leasts_correct, leasts_gpt)\n",
        "\n",
        "print(\"\\nComparing most illustrative pairs:\")\n",
        "compare_lists(mosts_correct, mosts_gpt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd6SSQur3Pm3",
        "outputId": "4ab60f4d-96ab-405b-f30e-42a14e788bbb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing least illustrative pairs:\n",
            "Mismatch at index 1: 'growl:danger' (List1) vs 'anger:slap' (List2)\n",
            "Mismatch at index 2: 'discourse:relationship' (List1) vs 'punch:hatred' (List2)\n",
            "Mismatch at index 3: 'frown:anger' (List1) vs 'handshake:cordiality' (List2)\n",
            "Mismatch at index 4: 'sigh:exhaustion' (List1) vs 'friendliness:wink' (List2)\n",
            "Mismatch at index 5: 'wink:friendliness' (List1) vs 'exhaustion:sigh' (List2)\n",
            "Mismatch at index 6: 'wave:acknowledgment' (List1) vs 'kiss:passion' (List2)\n",
            "Mismatch at index 9: 'exhaustion:sigh' (List1) vs 'discourse:relationship' (List2)\n",
            "Mismatch at index 10: 'glare:anger' (List1) vs 'sorrow:tears' (List2)\n",
            "Mismatch at index 13: 'hilarity:laugh' (List1) vs 'burp:gas' (List2)\n",
            "Mismatch at index 16: 'growl:danger' (List1) vs 'punch:hatred' (List2)\n",
            "Mismatch at index 17: 'glare:anger' (List1) vs 'handshake:cordiality' (List2)\n",
            "Mismatch at index 19: 'glare:anger' (List1) vs 'wave:acknowledgment' (List2)\n",
            "Mismatch at index 20: 'hilarity:laugh' (List1) vs 'slap:anger' (List2)\n",
            "Mismatch at index 21: 'frown:sadness' (List1) vs 'laugh:amusement' (List2)\n",
            "Mismatch at index 23: 'kiss:passion' (List1) vs 'punch:hatred' (List2)\n",
            "Mismatch at index 26: 'growl:danger' (List1) vs 'frown:sadness' (List2)\n",
            "Mismatch at index 27: 'sorrow:tears' (List1) vs 'anger:slap' (List2)\n",
            "Mismatch at index 29: 'wave:acknowledgment' (List1) vs 'slap:anger' (List2)\n",
            "Mismatch at index 32: 'snarl:anger' (List1) vs 'nod:agreement' (List2)\n",
            "Mismatch at index 33: 'glare:anger' (List1) vs 'kiss:passion' (List2)\n",
            "Mismatch at index 34: 'cough:illness' (List1) vs 'lie:dishonesty' (List2)\n",
            "Mismatch at index 35: 'hilarity:laugh' (List1) vs '' (List2)\n",
            "Mismatch at index 37: 'sigh:exhaustion' (List1) vs 'slap:anger' (List2)\n",
            "Mismatch at index 40: 'hilarity:laugh' (List1) vs 'cough:illness' (List2)\n",
            "Mismatch at index 41: 'frown:discontent' (List1) vs 'snarl:anger' (List2)\n",
            "Mismatch at index 42: 'frown:distaste' (List1) vs 'slap:anger' (List2)\n",
            "Mismatch at index 43: 'exhaustion:sigh' (List1) vs 'glare:anger' (List2)\n",
            "Mismatch at index 45: 'yawn:boredom' (List1) vs 'burp:gas' (List2)\n",
            "Mismatch at index 46: 'wink:friendliness' (List1) vs 'punch:hatred' (List2)\n",
            "Mismatch at index 48: 'friendliness:wink' (List1) vs 'anger:slap' (List2)\n",
            "Mismatch at index 50: 'nod:agreement' (List1) vs 'frown:distaste' (List2)\n",
            "Mismatch at index 51: 'crying:sadness' (List1) vs 'wave:acknowledgment' (List2)\n",
            "Mismatch at index 54: 'nod:agreement' (List1) vs 'burp:gas' (List2)\n",
            "Mismatch at index 56: 'exhaustion:sigh' (List1) vs 'anger:slap' (List2)\n",
            "Mismatch at index 57: 'handshake:cordiality' (List1) vs 'slap:anger' (List2)\n",
            "Mismatch at index 61: 'grimace:disgust' (List1) vs 'kiss:love' (List2)\n",
            "Mismatch at index 62: 'friendliness:wink' (List1) vs 'slap:anger' (List2)\n",
            "Mismatch at index 63: 'slap:anger' (List1) vs 'cough:illness' (List2)\n",
            "Mismatch at index 64: 'tears:sorrow' (List1) vs 'burp:gas' (List2)\n",
            "Mismatch at index 69: 'sorrow:tears' (List1) vs 'frown:anger' (List2)\n",
            "Mismatch at index 71: 'frown:anger' (List1) vs 'wave:acknowledgement' (List2)\n",
            "Mismatch at index 72: 'cough:illness' (List1) vs 'sorrow:tears' (List2)\n",
            "Mismatch at index 74: 'yawn:boredom' (List1) vs 'kiss:love' (List2)\n",
            "Mismatch at index 76: 'handshake:cordiality' (List1) vs 'hilarity:laugh' (List2)\n",
            "Mismatch at index 77: 'hilarity:laugh' (List1) vs 'laugh:happiness' (List2)\n",
            "Mismatch at index 78: 'discourse:relationship' (List1) vs 'cough:sickness' (List2)\n",
            "Mismatch at index 80: 'laugh:hilarity' (List1) vs 'cough:sickness' (List2)\n",
            "Mismatch at index 82: 'exhaustion:sigh' (List1) vs 'lie:dishonesty' (List2)\n",
            "Mismatch at index 84: 'friendliness:wink' (List1) vs 'sorrow:tears' (List2)\n",
            "Mismatch at index 87: 'tear:sadness' (List1) vs 'punch:hatred' (List2)\n",
            "Mismatch at index 88: 'tear:sadness' (List1) vs 'laugh:happiness' (List2)\n",
            "Mismatch at index 91: 'frown:sadness' (List1) vs 'tear:sadness' (List2)\n",
            "Mismatch at index 92: 'scream:terror' (List1) vs 'handshake:cordiality' (List2)\n",
            "Mismatch at index 93: 'frown:anger' (List1) vs 'burp:gas' (List2)\n",
            "Mismatch at index 97: 'tears:sadness' (List1) vs 'frown:discontent' (List2)\n",
            "Total matches: 45 out of 100\n",
            "\n",
            "Comparing most illustrative pairs:\n",
            "Mismatch at index 1: 'cough:sickness' (List1) vs 'crying:sadness' (List2)\n",
            "Mismatch at index 2: 'yell:anger' (List1) vs 'sigh:exhaustion' (List2)\n",
            "Mismatch at index 4: 'nod:agreement' (List1) vs 'yawn:boredom' (List2)\n",
            "Mismatch at index 5: 'kiss:love' (List1) vs 'frown:anger' (List2)\n",
            "Mismatch at index 6: 'kiss:passion' (List1) vs 'wave:acknowledgment' (List2)\n",
            "Mismatch at index 7: 'crying:sadness' (List1) vs 'snarl:anger' (List2)\n",
            "Mismatch at index 8: 'tear:sadness' (List1) vs 'yawn:boredom' (List2)\n",
            "Mismatch at index 10: 'sorrow:tears' (List1) vs 'frown:discontent' (List2)\n",
            "Mismatch at index 11: 'laugh:happiness' (List1) vs 'laughter:amusement' (List2)\n",
            "Mismatch at index 14: 'groan:pain' (List1) vs 'laughter:amusement' (List2)\n",
            "Mismatch at index 17: 'yawn:boredom' (List1) vs 'growl:danger' (List2)\n",
            "Mismatch at index 18: 'laugh:amusement' (List1) vs 'yell:anger' (List2)\n",
            "Mismatch at index 19: 'lie:dishonesty' (List1) vs 'frown:discontent' (List2)\n",
            "Mismatch at index 20: 'cough:sickness' (List1) vs 'frown:anger' (List2)\n",
            "Mismatch at index 21: 'snarl:anger' (List1) vs 'grimace:disgust' (List2)\n",
            "Mismatch at index 23: 'wave:acknowledgement' (List1) vs 'sigh:exhaustion' (List2)\n",
            "Mismatch at index 24: 'frown:discontent' (List1) vs 'growl:danger' (List2)\n",
            "Mismatch at index 27: 'laugh:happiness' (List1) vs 'wink:friendliness' (List2)\n",
            "Mismatch at index 29: 'lie:dishonesty' (List1) vs 'frown:sadness' (List2)\n",
            "Mismatch at index 30: 'laugh:amusement' (List1) vs 'growl:danger' (List2)\n",
            "Mismatch at index 32: 'crying:sadness' (List1) vs 'scream:terror' (List2)\n",
            "Mismatch at index 33: 'nod:agreement' (List1) vs 'glare:anger' (List2)\n",
            "Mismatch at index 34: 'lie:dishonesty' (List1) vs 'sigh:exhaustion' (List2)\n",
            "Mismatch at index 35: 'laugh:hilarity' (List1) vs '' (List2)\n",
            "Mismatch at index 36: 'grimace:disgust' (List1) vs 'tears:sadness' (List2)\n",
            "Mismatch at index 39: 'tears:sorrow' (List1) vs 'crying:sadness' (List2)\n",
            "Mismatch at index 40: 'cough:illness' (List1) vs 'frown:distaste' (List2)\n",
            "Mismatch at index 41: 'crying:sadness' (List1) vs 'tears:sorrow' (List2)\n",
            "Mismatch at index 43: 'tears:sadness' (List1) vs 'crying:sadness' (List2)\n",
            "Mismatch at index 44: 'frown:sadness' (List1) vs 'tears:sorrow' (List2)\n",
            "Mismatch at index 45: 'grimace:disgust' (List1) vs 'sigh:exhaustion' (List2)\n",
            "Mismatch at index 51: 'kiss:passion' (List1) vs 'yell:anger' (List2)\n",
            "Mismatch at index 53: 'kiss:love' (List1) vs 'yell:anger' (List2)\n",
            "Mismatch at index 54: 'frown:sadness' (List1) vs 'scream:terror' (List2)\n",
            "Mismatch at index 55: 'handshake:cordiality' (List1) vs 'growl:danger' (List2)\n",
            "Mismatch at index 57: 'slap:anger' (List1) vs 'laugh:happiness' (List2)\n",
            "Mismatch at index 59: 'grimace:disgust' (List1) vs 'nod:agreement' (List2)\n",
            "Mismatch at index 60: 'tears:sorrow' (List1) vs 'groan:pain' (List2)\n",
            "Mismatch at index 62: 'glare:anger' (List1) vs 'exhaustion:sigh' (List2)\n",
            "Mismatch at index 63: 'kiss:love' (List1) vs 'scream:terror' (List2)\n",
            "Mismatch at index 64: 'burp:gas' (List1) vs 'laugh:happiness' (List2)\n",
            "Mismatch at index 65: 'tears:sorrow' (List1) vs 'tears:sadness' (List2)\n",
            "Mismatch at index 67: 'tears:sadness' (List1) vs 'frown:anger' (List2)\n",
            "Mismatch at index 68: 'laughter:amusement' (List1) vs 'frown:anger' (List2)\n",
            "Mismatch at index 69: 'snarl:anger' (List1) vs 'sorrow:tears' (List2)\n",
            "Mismatch at index 70: 'laugh:amusement' (List1) vs 'kiss:love' (List2)\n",
            "Mismatch at index 71: 'snarl:anger' (List1) vs 'groan:pain' (List2)\n",
            "Mismatch at index 73: 'grimace:disgust' (List1) vs 'yell:anger' (List2)\n",
            "Mismatch at index 74: 'laughter:amusement' (List1) vs 'tear:sadness' (List2)\n",
            "Mismatch at index 76: 'laugh:amusement' (List1) vs 'handshake:cordiality' (List2)\n",
            "Mismatch at index 77: 'laugh:happiness' (List1) vs 'hilarity:laugh' (List2)\n",
            "Mismatch at index 78: 'kiss:love' (List1) vs 'discourse:relationship' (List2)\n",
            "Mismatch at index 79: 'sigh:exhaustion' (List1) vs 'crying:sadness' (List2)\n",
            "Mismatch at index 81: 'lie:dishonesty' (List1) vs 'frown:sadness' (List2)\n",
            "Mismatch at index 82: 'tear:sadness' (List1) vs 'laugh:hilarity' (List2)\n",
            "Mismatch at index 83: 'wave:acknowledgement' (List1) vs 'laugh:hilarity' (List2)\n",
            "Mismatch at index 84: 'sorrow:tears' (List1) vs 'laugh:hilarity' (List2)\n",
            "Mismatch at index 85: 'cough:illness' (List1) vs 'glare:anger' (List2)\n",
            "Mismatch at index 87: 'cough:sickness' (List1) vs 'tear:sadness' (List2)\n",
            "Mismatch at index 88: 'sigh:exhaustion' (List1) vs 'frown:anger' (List2)\n",
            "Mismatch at index 89: 'laughter:amusement' (List1) vs 'wave:acknowledgment' (List2)\n",
            "Mismatch at index 90: 'tear:sadness' (List1) vs 'frown:discontent' (List2)\n",
            "Mismatch at index 91: 'tear:sadness' (List1) vs 'scream:terror' (List2)\n",
            "Mismatch at index 92: 'handshake:cordiality' (List1) vs 'scream:terror' (List2)\n",
            "Mismatch at index 94: 'nod:agreement' (List1) vs 'growl:danger' (List2)\n",
            "Mismatch at index 96: 'laugh:happiness' (List1) vs 'yell:anger' (List2)\n",
            "Mismatch at index 97: 'kiss:love' (List1) vs 'laughter:amusement' (List2)\n",
            "Mismatch at index 98: 'groan:pain' (List1) vs 'scream:terror' (List2)\n",
            "Total matches: 32 out of 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistics for matching data\n",
        "\n",
        "# 1c\n",
        "# least - 51 out of 105\n",
        "# most - 25 out of 105\n",
        "# Modification made:\n",
        "# leasts_gpt.insert(20, '')\n",
        "# mosts_gpt.insert(1, '')\n",
        "\n",
        "# 2a\n",
        "# least - 46 out of 110\n",
        "# most - 44 out of 110\n",
        "\n",
        "# 2g\n",
        "# least - 51 out of 108\n",
        "# most - 57 out of 108\n",
        "\n",
        "# 4b\n",
        "# least - 26 out of 88\n",
        "# most - 36 out of 88\n",
        "\n",
        "# 4d\n",
        "# least - 40 out of 75\n",
        "# most - 43 out of 75\n",
        "\n",
        "# 6d\n",
        "# least - 34 out of 113\n",
        "# most - 45 out of 113\n",
        "\n",
        "# 10b\n",
        "# Modification made:\n",
        "# leasts_gpt.insert(35, '')\n",
        "# mosts_gpt.insert(35, '')\n",
        "# least - 45 out of 100\n",
        "# most - 32 out of 100"
      ],
      "metadata": {
        "id": "lcaL2LXF2uNM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Data to be displayed\n",
        "data = [\n",
        "    {\"id\": \"1c\", \"least\": \"51 out of 105\", \"most\": \"25 out of 105\", \"notes\": \"leasts_gpt.insert(20, ''), mosts_gpt.insert(1, '')\"},\n",
        "    {\"id\": \"2a\", \"least\": \"46 out of 110\", \"most\": \"44 out of 110\", \"notes\": \"\"},\n",
        "    {\"id\": \"2g\", \"least\": \"51 out of 108\", \"most\": \"57 out of 108\", \"notes\": \"\"},\n",
        "    {\"id\": \"4b\", \"least\": \"26 out of 88\", \"most\": \"36 out of 88\", \"notes\": \"\"},\n",
        "    {\"id\": \"4d\", \"least\": \"40 out of 75\", \"most\": \"43 out of 75\", \"notes\": \"\"},\n",
        "    {\"id\": \"6d\", \"least\": \"34 out of 113\", \"most\": \"45 out of 113\", \"notes\": \"\"},\n",
        "    {\"id\": \"10b\", \"least\": \"45 out of 100\", \"most\": \"32 out of 100\", \"notes\": \"leasts_gpt.insert(35, ''), mosts_gpt.insert(35, '')\"}\n",
        "]\n",
        "\n",
        "# Create a PrettyTable\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"ID\", \"Least Illustrative\", \"Most Illustrative\", \"Modification Notes\"]\n",
        "\n",
        "# Adding rows to the table\n",
        "for entry in data:\n",
        "    table.add_row([entry[\"id\"], entry[\"least\"], entry[\"most\"], entry[\"notes\"]])\n",
        "\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n0lqoe68Iy4",
        "outputId": "43572e69-a14f-4de2-b2ff-f1f91344527b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+-------------------+-----------------------------------------------------+\n",
            "|  ID | Least Illustrative | Most Illustrative |                  Modification Notes                 |\n",
            "+-----+--------------------+-------------------+-----------------------------------------------------+\n",
            "|  1c |   51 out of 105    |   25 out of 105   |  leasts_gpt.insert(20, ''), mosts_gpt.insert(1, '') |\n",
            "|  2a |   46 out of 110    |   44 out of 110   |                                                     |\n",
            "|  2g |   51 out of 108    |   57 out of 108   |                                                     |\n",
            "|  4b |    26 out of 88    |    36 out of 88   |                                                     |\n",
            "|  4d |    40 out of 75    |    43 out of 75   |                                                     |\n",
            "|  6d |   34 out of 113    |   45 out of 113   |                                                     |\n",
            "| 10b |   45 out of 100    |   32 out of 100   | leasts_gpt.insert(35, ''), mosts_gpt.insert(35, '') |\n",
            "+-----+--------------------+-------------------+-----------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}